# 최종 보고서

## 프로젝트 주제 **: “서울 지하철 혼잡도 예측 대시보드”**

- 프로젝트 기간 : 2024.11.01 ~ 2024.11.06
- 프로젝트 인원 : 7인

---

> **목 차**
> 

---

# 1. 프로젝트 개요

## 1.1 프로젝트 배경

- 서울은 인구 밀집 지역으로, 지하철은 대중교통의 핵심입니다. 그러나 특정 시간대에는 **혼잡도가 급증**하여 **시민들의 통근 및 이동에 불편을 초래**하고 있습니다. 이러한 문제를 해결하기 위해, 서울시 지하철의 혼잡도를 예측하고 이에 대한 정보를 제공하는 시스템의 필요성이 대두되었습니다.
- 본 프로젝트는 공공 데이터를 활용하여 지하철 혼잡도를 예측하고, 이를 시각화하여 이용자들이 혼잡한 시간대를 피할 수 있도록 도와주고자 합니다.

## 1.2 프로젝트 목표

<aside>

**“서울시 지하철의 혼잡도를 예측하고 시각화하여
시민들의 보다 효율적인 대중교통 이용을 도모하고자 함”**

</aside>

- **데이터 수집 및 분석** : 서울시의 다양한 지하철 관련 공공 데이터를 수집하고, 데이터 전처리를 통해 혼잡도를 분석합니다.
- **대시보드 시각화** : 분석결과를 시각적으로 표현하여 사용자들이 직관적으로 혼잡도를 확인할 수 있는 대시보드를 구축합니다.
- **정보 제공 및 사용자 편의성 향상** : 대시보드를 통해 시민들이 보다 효율적으로 지하철을 이용할 수 있도록 정보를 제공합니다.

# 2. 활용 기술

## 2.1 기술스택

| **구분** | **기술/도구** | **용도** |
| --- | --- | --- |
| **데이터 수집** | 공공 데이터 포털 | 공공 데이터 API 다운로드 |
| ETL | Python | Open API로부터 데이터 수집 후 전처리 후 S3에 적재  |
| Data Lake | AWS S3 | 데이터 저장 및 관리 |
| Data Warehouse | Snowflake | 데이터 웨어하우스 및 분석 |
| **대시보드 시각화** | Superset | 데이터 시각화 및 대시보드 구성 |
| **협업 도구** | Notion | 문서 관리 및 프로젝트 관리 |
|  | Slack | 팀 소통 및 협업 |
|  | Zep | 실시간 협업(카메라, 마이크) |

## 2.2 협업 활동

- Zep


- Slack


# 3. 프로젝트 구현 과정

## 3.1 데이터 수집 및 전처리

### 3.1.1 데이터 출처

- 지하철혼잡도정보

[서울교통공사_지하철혼잡도정보_20240930](https://www.data.go.kr/data/15071311/fileData.do)

- 역별 일별 시간대별 승하차인원 정보

[서울교통공사_역별 일별 시간대별 승하차인원 정보_20230930](https://www.data.go.kr/data/15048032/fileData.do)

### 3.1.2 데이터 전처리 과정

- **데이터 수집 단계**
    - 공공 데이터 포털의 Open API를 활용하여 지하철혼잡도정보 & 월별 승하차인원 & 역별 일별 시간대별 승하차인원 데이터 수집
        
        
    - Python의 pandas 라이브러리를 활용하여 데이터 전처리
        - https://github.com/yjbenkang/seoul-metro-data-project
    - AWS S3 데이터 레이크에 전처리 완료된 csv포맷의 데이터 적재
        
        
    - Snowflake에서 AWS S3 버킷에 접근 가능하게끔 IAM 사용자 및 액세스키&시크릿키 생성

## 3.2 데이터 파이프라인 설계

### S3 - Snowflake Connection

- IAM 사용자 생성 및 권한 부여
- Access key 및 Private key 생성

### Snowflake Data Load


- raw_data, analytics, adhoc Schema 생성
- S3 데이터  Copy를 통해 Raw_data Schema 벌크업데이트 진행

### Snowflake에서 추가 데이터 전처리 작업 진행

- 결측치 및 이상치 제거
- 테이블 시간 데이터 pivoting 작업
    
    
- 첫차시간 ~ 막차시간 indexing 작업
    
    
- 이후 Analytics Schema에 Load

### Snowflake - Preset Connection


- Preset에서 IP Allowlist 확인


- Snowflake에서 Admin - Security - Network Rules에서 IPV4로 Allowlist IP 추가
- Network Policies 생성 → Active 실행


- Admin에서 확인할 수 있는 정보를 바탕으로 Blank를 채우고 Connect
- 이후 Dataset 연결하여 대시보드 시각화 진행

## 3.3 대시보드 설계 및 구현

- **대시보드 요구 사항 정의**
    - 사용자 요구 사항 및 기능 정의 - 피그마를 이용해 스케치 작성
    
    
- **데이터 시각화 요소**
    - 메인 보드
        - 혼잡도 시간대별 그래프, 요일별 혼잡도 변화 시각화
    
    
    - 필터 별 상세 보드
    
     
    - 필터로 원하는 호선이나 역의 혼잡도를 조회할 수 있다.

# 4. 결과 및 분석

## 4.1 데이터 분석 결과

### 4.1.1 시간대별 혼잡도 분석


- 첫차(05:30)부터 막차(00:30)까지의 전체 노선의 시간대별 혼잡도 분석을 하였습니다. 서울교통공사가 분석한 혼잡도를 전체 호선과 역에 대해 평균값을 내 시각화하였습니다.
- **출퇴근 시간 피크**: 출퇴근 시간대의 혼잡도를 분석하여 특정 시간대에 가장 혼잡한 구간을 파악합니다. 오전 7시부터 10시까지, 오후 4시부터 7시까지 방향에 상관없이 혼잡한 것이 공통적으로 드러났습니다.
- **비교적 한가한 시간대**: 혼잡도가 낮은 시간대를 확인하여 승객들에게 추천할 수 있는 시간대를 제시합니다. 오전 6시에 혼잡도가 일시적으로 감소하며 오후 7시부터 혼잡도가 눈에 띄게 줄어드는 것을 볼 수 있습니다.

### 4.1.2 요일별 혼잡도 패턴


- **특정 요일의 혼잡도**: 월요일, 금요일 등 특정 요일에 따른 혼잡도 변화를 분석하여, 요일 별 특징을 도출했습니다.
- 주중에 비해 주말에 이용객이 적으며, 일요일에 가장 적은 인원이 이용하는 양상을 보임을 알 수 있습니다.

### 4.1.3 호선별 혼잡도 비교


- **가장 혼잡한 호선** : 호선별 평균 혼잡도를 비교 분석한 결과, 가장 혼잡한 호선은 2호선으로 파악됩니다. 그외에도 7호선, 3,4호선 순으로 혼잡한 것을 알 수 있습니다.
- **비교적 덜 혼잡한 호선** : 혼잡도가 상대적으로 낮은 호선은 6호선입니다.
- 지하철을 이용하는 승하차승객의 쾌적한 환경과 안전을 위해 혼잡도를 개선한다면 가장 시급한 2호선부터 개선이 필요할 것으로 보입니다.

## 4.2 기대효과

- **대중교통 이용 패턴 분석**: 수집된 데이터를 기반으로 특정 노선과 시간대에 따른 이용 패턴을 분석하여 운영 효율성을 제고할 수 있는 인사이트를 제공합니다.
- **시민 편의성 증대**: 실시간 데이터와 예측 결과를 바탕으로 시민들에게 혼잡도를 사전 안내함으로써 대중교통 이용의 편의성을 높입니다.

# 5. 회고 및 개선점

## 5.1 팀원 역할 및 기여도

| **팀원** | **역할** | **기여도** |
| --- | --- | --- |
| 강용진 | 데이터 전처리 및 S3 업로드 | 15% |
| 김민규 | 데이터 파이프라인 설계 | 15% |
| 김효정 | 대시보드 시각화 | 15% |
| 박건현 | 대시보드 시각화 | 15% |
| 이민지 | 대시보드 시각화, 보고서, ppt 작성 | 15% |
| 이준호 | 데이터 파이프라인 설계 | 15% |
| 임태현 | 데이터 전처리 및 S3 업로드 | 15% |

## 5.2 느낀점

| **팀원** | **느낀점** |
| --- | --- |
| 강용진 | S3 Datalake에 데이터를 전처리 및 적재하는 과정을 수행함으로써 데이터 수집 및 적재까지의 과정을 경험해볼 수 있는 좋은 기회였다고 생각합니다. |
| 김민규 | S3 - Snowflake - Preset 데이터 파이프라인 구축을 담당하여 ETL 및 데이터 파이프라인 구축 과정을 직접 진행하여 파이프라인에 대해 자세히 공부하는 계기가 되었습니다 |
| 김효정 | 데이터 시각화를 처음 경험해 보았습니다. 처음에는 엑셀로 시각화하는 게 더 편하지 않나 생각했는데 프리셋이라는 데이터 시각화 툴을 사용하는 게 더욱 많은 종류의 시각화를 할 수 있다는 것을 알게 되었습니다. 시각화를 구현하기 위해서 어떤 종류의 데이터를 원하는지 알려드리는게 일의 우선순위가 높다는 것을 배웠습니다. |
| 박건현 |  |
| 이민지 | 데이터 시각화 툴을 처음으로 다뤄본 좋은 경험이었습니다. 시각화를 구현하는 과정도 만만치 않다는 것을 알게 되었고 유의미한 결과를 도출하기 위해 데이터 구축 및 전처리 하는 팀과의 유기적인 소통도 필수적이라는 걸 알게 되었습니다 |
| 이준호 | 데이터 파이프라인 구축 과정을 이론으로만 배우고 직접 프로젝트를 통해 경험해본 것은 처음이었는데, 실제 데이터를 가지고 데이터 인프라를 경험해보니 이론만 배울 때보다 훨씬 와닿게 배울 수 있었고 좋은 경험이 된 것 같습니다. |
| 임태현 | API를 이용해서 데이터를 받고 전처리 하는 과정을 수행하고 S3에 데이터를 적재하는 과정을 경험하면서 효율적인 데이터의 접근과 공유성을 느꼈습니다.  |

## 5.3 개선 및 발전 방향

- 데이터 수집 & 전처리
    - 현재 데이터 수집 시 이중 for문의 시간복잡도는 n^2이므로 쓰레드 처리를 통해 현재 직렬로 처리되는 코드를 병렬로 처리할 필요가 있음
- 데이터 파이프라인
    - Redshift로도 진행하여 Snowflake와 비교 진행
    - Analytics Role  부여
- 대시보드 시각화
    - 시간대별 혼잡도 그래프 표현시 지하철 운행시간(5:30~00:30)을 시간순서대로 표현하면 00시, 00시 30분이 시작부분으로 표현되는 문제를 첫차 시간대(5:30)부터 시작하는 그래프로 조정이 필요
    - 필터별 상세 대시보드 막대 그래프에 색 변화를 주어 더욱 구별할 수 있게 만들면 좋을 것 같다
    - 특정 호선의 경우 새벽 1시까지 운행하여 데이터 통일이 필요하다