{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z9AbF9rFqGwl",
    "outputId": "ee66d703-0ee3-4cbd-f9a0-7505d4c2d1fb",
    "ExecuteTime": {
     "end_time": "2024-11-04T07:39:58.269172Z",
     "start_time": "2024-11-04T07:39:57.028455Z"
    }
   },
   "source": [
    "!pip install requests boto3\n",
    "!pip install python-dotenv"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/yjbenkang/miniconda3/lib/python3.12/site-packages (2.31.0)\r\n",
      "Requirement already satisfied: boto3 in /Users/yjbenkang/miniconda3/lib/python3.12/site-packages (1.35.54)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yjbenkang/miniconda3/lib/python3.12/site-packages (from requests) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yjbenkang/miniconda3/lib/python3.12/site-packages (from requests) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yjbenkang/miniconda3/lib/python3.12/site-packages (from requests) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yjbenkang/miniconda3/lib/python3.12/site-packages (from requests) (2024.8.30)\r\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.54 in /Users/yjbenkang/miniconda3/lib/python3.12/site-packages (from boto3) (1.35.54)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/yjbenkang/miniconda3/lib/python3.12/site-packages (from boto3) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/yjbenkang/miniconda3/lib/python3.12/site-packages (from boto3) (0.10.3)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/yjbenkang/miniconda3/lib/python3.12/site-packages (from botocore<1.36.0,>=1.35.54->boto3) (2.9.0.post0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/yjbenkang/miniconda3/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.54->boto3) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: python-dotenv in /Users/yjbenkang/miniconda3/lib/python3.12/site-packages (1.0.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import os \n",
    "from dotenv import load_dotenv"
   ],
   "metadata": {
    "id": "mI31ir7RqRvR",
    "ExecuteTime": {
     "end_time": "2024-11-04T07:39:58.275563Z",
     "start_time": "2024-11-04T07:39:58.271446Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "base_url = os.getenv(\"BASE_URL\")\n",
    "aws_access_key_id=os.getenv('S3_AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key=os.getenv('S3_AWS_SECRET_ACCESS_KEY')\n",
    "region_name=os.getenv('S3_REGION')\n",
    "bucket_name = os.getenv('S3_BUCKET_NAME')"
   ],
   "metadata": {
    "id": "GOrlDYOyqvh5",
    "ExecuteTime": {
     "end_time": "2024-11-04T07:39:58.282729Z",
     "start_time": "2024-11-04T07:39:58.276989Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "bucket_name = bucket_name"
   ],
   "metadata": {
    "id": "MnHBYta83LTM",
    "ExecuteTime": {
     "end_time": "2024-11-04T07:39:58.773545Z",
     "start_time": "2024-11-04T07:39:58.720194Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "def fetch_and_save_data(api_endpoints, output_file):\n",
    "    \"\"\"\n",
    "    여러 API 엔드포인트에서 데이터를 가져와 하나의 CSV 파일로 저장 후 S3에 업로드합니다.\n",
    "\n",
    "    Parameters:\n",
    "    - api_endpoints (list): 데이터를 가져올 API 엔드포인트 목록.\n",
    "    - output_file (str): S3에 저장할 파일 이름.\n",
    "    \"\"\"\n",
    "    # 모든 데이터를 누적할 DataFrame 초기화\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    # 각 API 엔드포인트에서 데이터 가져오기\n",
    "    for endpoint, date in api_endpoints.items():\n",
    "        page = 1\n",
    "        per_page = 1000\n",
    "        \n",
    "        while True:\n",
    "            url = f\"{base_url}{endpoint}?page={page}&perPage={per_page}&serviceKey={api_key}\"\n",
    "            \n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                if 'data' in data and data['data']:\n",
    "                    df = pd.DataFrame(data['data'])\n",
    "                    df['date'] = date\n",
    "                    # 컬럼 이름 통일하기\n",
    "                    df.rename(columns={\n",
    "                        '5시30분': '05_30',\n",
    "                        '6시00분': '06_00',\n",
    "                        '6시30분': '06_30',\n",
    "                        '7시00분': '07_00',\n",
    "                        '7시30분': '07_30',\n",
    "                        '8시00분': '08_00',\n",
    "                        '8시30분': '08_30',\n",
    "                        '9시00분': '09_00',\n",
    "                        '9시30분': '09_30',\n",
    "                        '10시00분': '10_00',\n",
    "                        '10시30분': '10_30',\n",
    "                        '11시00분': '11_00',\n",
    "                        '11시30분': '11_30',\n",
    "                        '12시00분': '12_00',\n",
    "                        '12시30분': '12_30',\n",
    "                        '13시00분': '13_00',\n",
    "                        '13시30분': '13_30',\n",
    "                        '14시00분': '14_00',\n",
    "                        '14시30분': '14_30',\n",
    "                        '15시00분': '15_00',\n",
    "                        '15시30분': '15_30',\n",
    "                        '16시00분': '16_00',\n",
    "                        '16시30분': '16_30',\n",
    "                        '17시00분': '17_00',\n",
    "                        '17시30분': '17_30',\n",
    "                        '18시00분': '18_00',\n",
    "                        '18시30분': '18_30',\n",
    "                        '19시00분': '19_00',\n",
    "                        '19시30분': '19_30',\n",
    "                        '20시00분': '20_00',\n",
    "                        '20시30분': '20_30',\n",
    "                        '21시00분': '21_00',\n",
    "                        '21시30분': '21_30',\n",
    "                        '22시00분': '22_00',\n",
    "                        '22시30분': '22_30',\n",
    "                        '23시00분': '23_00',\n",
    "                        '23시30분': '23_30',\n",
    "                        '24시00분': '00_00',\n",
    "                        '24시30분': '00_30',\n",
    "                        '00시00분': '00_00',\n",
    "                        '00시30분': '00_30',\n",
    "                        '상하구분': 'direction',\n",
    "                        '구분': 'direction',\n",
    "                        '출발역': 'departure_station',\n",
    "                        '역명': 'departure_station',\n",
    "                        '요일구분': 'day_type',\n",
    "                        '조사일자': 'day_type',\n",
    "                        '역번호': 'station_number',\n",
    "                        '호선': 'line'\n",
    "                    }, inplace=True)\n",
    "\n",
    "                    if '연번' in df.columns:\n",
    "                        df.drop(columns=['연번'], inplace=True)\n",
    "                    all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "                    print(f\"{endpoint} - Page {page} data fetched and added.\")\n",
    "                else:\n",
    "                    print(f\"No more data to fetch for {endpoint}.\")\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"Failed to fetch data from {endpoint} on page {page}: {response.status_code}\")\n",
    "                break\n",
    "\n",
    "            page += 1\n",
    "\n",
    "    # 최종 데이터를 CSV로 변환하고 S3에 업로드\n",
    "    csv_buffer = BytesIO()\n",
    "    all_data.to_csv(csv_buffer, index=False, encoding='utf-8')\n",
    "    csv_buffer.seek(0)\n",
    "\n",
    "    try:\n",
    "        s3_client.upload_fileobj(csv_buffer, bucket_name, output_file)\n",
    "        print(f\"모든 데이터가 {output_file} 파일로 S3에 성공적으로 업로드되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to upload combined data to S3: {e}\")\n",
    "\n",
    "api_endpoints = {\n",
    "    \"/15071311/v1/uddi:70e3a3d3-0872-4828-8234-f0bca459b44f\": \"20191231\",\n",
    "    \"/15071311/v1/uddi:b3803d43-ffe3-4d17-9024-fd6cfa37c284\": \"20211231\",\n",
    "    \"/15071311/v1/uddi:75461a18-17a3-42fe-9322-a51148003b69\": \"20221231\",\n",
    "    \"/15071311/v1/uddi:99771417-a036-46f1-8ad5-8edf4591c2ee\": \"20201231\",\n",
    "    \"/15071311/v1/uddi:e477f1d9-2c3a-4dc8-b147-a55584583fa2\": \"20231231\",\n",
    "    \"/15071311/v1/uddi:c87b6af0-0ef7-4182-b172-fd2680a79d6f\": \"20240331\",\n",
    "    \"/15071311/v1/uddi:9aff0ee6-26e7-42c4-af0c-84bf31680ca9\": \"20240630\",\n",
    "    \"/15071311/v1/uddi:da7cd08f-94f0-4dba-b33d-d02dcb35b57b\": \"20240930\"\n",
    "}\n",
    "\n",
    "output_file = \"prod_data/서울교통공사_지하철혼잡도_전체데이터.csv\"\n",
    "fetch_and_save_data(api_endpoints, output_file)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iooq0sYkru10",
    "outputId": "beda1179-4498-4379-878d-08cad1f48f42",
    "ExecuteTime": {
     "end_time": "2024-11-04T07:49:28.512565Z",
     "start_time": "2024-11-04T07:49:18.611223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/15071311/v1/uddi:70e3a3d3-0872-4828-8234-f0bca459b44f - Page 1 data fetched and added.\n",
      "/15071311/v1/uddi:70e3a3d3-0872-4828-8234-f0bca459b44f - Page 2 data fetched and added.\n",
      "No more data to fetch for /15071311/v1/uddi:70e3a3d3-0872-4828-8234-f0bca459b44f.\n",
      "/15071311/v1/uddi:b3803d43-ffe3-4d17-9024-fd6cfa37c284 - Page 1 data fetched and added.\n",
      "/15071311/v1/uddi:b3803d43-ffe3-4d17-9024-fd6cfa37c284 - Page 2 data fetched and added.\n",
      "No more data to fetch for /15071311/v1/uddi:b3803d43-ffe3-4d17-9024-fd6cfa37c284.\n",
      "/15071311/v1/uddi:75461a18-17a3-42fe-9322-a51148003b69 - Page 1 data fetched and added.\n",
      "/15071311/v1/uddi:75461a18-17a3-42fe-9322-a51148003b69 - Page 2 data fetched and added.\n",
      "No more data to fetch for /15071311/v1/uddi:75461a18-17a3-42fe-9322-a51148003b69.\n",
      "/15071311/v1/uddi:99771417-a036-46f1-8ad5-8edf4591c2ee - Page 1 data fetched and added.\n",
      "/15071311/v1/uddi:99771417-a036-46f1-8ad5-8edf4591c2ee - Page 2 data fetched and added.\n",
      "No more data to fetch for /15071311/v1/uddi:99771417-a036-46f1-8ad5-8edf4591c2ee.\n",
      "/15071311/v1/uddi:e477f1d9-2c3a-4dc8-b147-a55584583fa2 - Page 1 data fetched and added.\n",
      "/15071311/v1/uddi:e477f1d9-2c3a-4dc8-b147-a55584583fa2 - Page 2 data fetched and added.\n",
      "No more data to fetch for /15071311/v1/uddi:e477f1d9-2c3a-4dc8-b147-a55584583fa2.\n",
      "/15071311/v1/uddi:c87b6af0-0ef7-4182-b172-fd2680a79d6f - Page 1 data fetched and added.\n",
      "/15071311/v1/uddi:c87b6af0-0ef7-4182-b172-fd2680a79d6f - Page 2 data fetched and added.\n",
      "No more data to fetch for /15071311/v1/uddi:c87b6af0-0ef7-4182-b172-fd2680a79d6f.\n",
      "/15071311/v1/uddi:9aff0ee6-26e7-42c4-af0c-84bf31680ca9 - Page 1 data fetched and added.\n",
      "/15071311/v1/uddi:9aff0ee6-26e7-42c4-af0c-84bf31680ca9 - Page 2 data fetched and added.\n",
      "No more data to fetch for /15071311/v1/uddi:9aff0ee6-26e7-42c4-af0c-84bf31680ca9.\n",
      "/15071311/v1/uddi:da7cd08f-94f0-4dba-b33d-d02dcb35b57b - Page 1 data fetched and added.\n",
      "/15071311/v1/uddi:da7cd08f-94f0-4dba-b33d-d02dcb35b57b - Page 2 data fetched and added.\n",
      "No more data to fetch for /15071311/v1/uddi:da7cd08f-94f0-4dba-b33d-d02dcb35b57b.\n",
      "모든 데이터가 prod_data/서울교통공사_지하철혼잡도_전체데이터.csv 파일로 S3에 성공적으로 업로드되었습니다.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
